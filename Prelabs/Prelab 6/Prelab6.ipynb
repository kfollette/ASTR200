{"nbformat":4,"nbformat_minor":0,"metadata":{"anaconda-cloud":{},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"Prelab6.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true}},"cells":[{"cell_type":"markdown","metadata":{"id":"nQCPURpILg80"},"source":["### *** Names: [Insert Your Name Here]***"]},{"cell_type":"markdown","metadata":{"id":"v1dJ5q8iLg84"},"source":["# Prelab 6 - Visualizing and Filtering Tabular Data\n","\n","##  Prelab 6 Contents\n","\n","1. Introduction to the NASA Exoplanet Archive Dataset\n","2. Creating Statistical Graphics from Pandas DataFrames\n","3. Filtering/Selecting a Subset of Data"]},{"cell_type":"code","metadata":{"id":"kRJrvKl-Lg85"},"source":["#various things that we will need\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","import scipy.stats as st\n","import seaborn as sb # a new plotting library"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vq6MNRL6Lg85"},"source":["# these set the pandas defaults so that it will print ALL values, even for very long lists and large dataframes\n","pd.set_option('display.max_columns', None)\n","pd.set_option('display.max_rows', None)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1MLAw8ePVtcW"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"--nFWSqXTBq6"},"source":["## 1. Introduction to the NASA Exoplanet Archive Dataset\n","\n","Most of the rest of this unit (and your second project) will revolve around a single dataset - the [NASA Exoplanet Archive](https://exoplanetarchive.ipac.caltech.edu/index.html).  \n","\n","We will explore this dataset in great detail and apply many of the statistical principles that you have learned and will be learning to it. For this prelab, you will begin just by exploring it. At a minimum, you should complete each of the following, but it may behoove you to do a little more exploring as well. For each item in the list below, you should include one or more well-commented code cells and/or a markdown cell with explanations.\n","\n","---\n","###Exercise 1\n","---\n","a) Figure out how to read in the data from the file planets_032821.csv into a dataframe called ```data```. (Hint: you will need to tell Pandas how many rows to skip before the real table begins) and print its shape. You will probably want to avoid displaying the dataframe itself in this notebook for now, as it is very large and will slow down your notebook. \n","\n","b) Use the exploratory pandas functions that you already know to find out basic information about the table and the types of entries in it, and write a 1 paragraph description of what the exoplanet archive is/contains based on these results. It may behoove you to do some googling of any new terms, or to refer to [this Astronomy jargon dictionary](https://docs.google.com/document/d/1sLHNH8eOdbiF976ITBlYeP2iv0-voBHO4pVBTXUDlHc/edit?usp=sharing).  \n","\n","c) Choose a single column that interests you and compute at least three descriptive statistics for it. Write a paragraph describing that variable in words. For example, a good explanation might look like the paragraph below (from a different dataset):  \n","\n",">QuaRCS score can take discrete integer values between 0 and 25. The minimum score for this dataset is 1 and the maximum is 25. There are 2,777 valid entries for score in this QuaRCS dataset, for which the mean is 13.9 and the median is 14 (both 56% of the maximum score). These are very close together, suggesting a reasonably centrally-concentrated score distrubution, and the low skewness value of 0.1 supports this. The kurtosis of the distribution is negative (platykurtic), which tells us that the distribution of scores is flat rather than peaky. The most common score (\"mode\") is 10, with 197 (~7%) of participants getting this score, however all score values from 7-21 have counts of greater than 100, supporting the flat nature of the distribution suggested by the negative kurtosis. The interquartile range (25-75 percentiles) is 8 points, and the standard deviation is 5.3. These represent a large fraction (20 and 32%) of the entire available score range, respectively, making the distribution quite wide."]},{"cell_type":"code","metadata":{"id":"FTm8N0yyLg86"},"source":["##insert code and markdown cells here as needed to answer Exercise 1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UkuK2-lLLg86"},"source":["---\n","\n","Now, to make the dataset a bit more manageable for plotting, we'll truncate it to include only planet discovery methods that have found more than 30 planets and also only things that are legitimately classified as planets (masses < 13 Jupiter masses). You don't have to understand everything that's going on in the cell below, however some of the techniques employed may be useful to you later, so I recommend you spend a few minutes trying to undertsand what's going on. (***Note: as instructed above, your dataframe needs to be named*** ```data``` ***for this cell to work***)"]},{"cell_type":"code","metadata":{"id":"sgSo5_xMLg86"},"source":["#this truncates to only planet detection methods with >30 successful detections (skip if you want all of them)\n","methods,methods_inds,methods_counts = np.unique(data['discoverymethod'],return_index=True,return_counts=True)\n","methods = methods[methods_counts> 30]\n","print(\"I am keeping only the following discovery methods: \", methods)\n","\n","#find the indices of all entries where discoverymethod is one of these five and the planet is really a planet (mass < 13*mass of jupiter)\n","inds = [j for j in range(len(data)) if data['discoverymethod'][j] in methods and data['pl_bmassj'][j] < 13.]\n","\n","#write a new dataframe with just these entries\n","data2 = data.loc[inds]\n","\n","#note the table is much smaller than it once was\n","print(\"My shape is now: \", data2.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QcuupVuOLg86"},"source":["## 2. Creating Statistical Graphics from Pandas DataFrames\n","\n","The exercises in this lab have many parallels with the exercises you did for the American Institute of Physics data that you looked at last week in Prelab/Lab 5. In this case, you will be introduced a bit more systematically to how to make a range of visualizations with Pandas dataframes and will use them to explore the dataset that you'll use for Project 2 in this course. ***As you work through this prelab and the remaining labs and prelabs in this unit, you should remain on the lookout for an interesting pattern or phenomenon that you want to explore more deeply in your project.***"]},{"cell_type":"markdown","metadata":{"id":"im0la-yfLg87"},"source":[" ## Statistical Plots for Pandas dataframes\n","---\n","### Exercise 2a - Histogram\n","---\n","The built-in syntax for creating a histogram for a pandas dataframe column is: \n","\n","```dataframe[\"Column Name\"].hist(bins=nbins)```\n","    \n","*HOWEVER*, the matplotlib built-in functionality is far more versatile and so I would like you to use it. To read in a pandas column as an array, follow this convention. \n","\n","```myarray = dataframe[\"Column Name\"].values```\n","\n","(i) Play around with inputs (e.g. column name) until you find a case (dataframe column) where you think the histogram tells you something important or interesting (you should play around with the number of bins as well). Display your histogram and then write a 2-3 sentence explanation of what it shows.    \n","    \n","(ii) Play around some more until you find an example where the histogram is not a particularly good way to represent the data. Explain why in 2-3 sentences.   \n","    \n","(iii) Now think more broadly. When are histograms useful and when aren't they? How many and what types of variables are they good at representing? What do they show that other types of plots don't and what don't they show that other types of plots do? "]},{"cell_type":"code","metadata":{"id":"ymcYOGvDLg87"},"source":["#informative histogram here"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"w_EX5CD7Lg87"},"source":["*informative histogram description here*"]},{"cell_type":"code","metadata":{"id":"FluUZzv-Lg87"},"source":["#uninformative histogram here"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PpNIoNt0Lg87"},"source":["*uninformative histogram description here*"]},{"cell_type":"markdown","metadata":{"id":"oOXnI-ClLg87"},"source":["*Part iii explanation here*"]},{"cell_type":"markdown","metadata":{"id":"JeqELpVVLg88"},"source":["--- \n","### Exercise 2b - Box plots\n","---\n","You made notched boxplots with the seaborn plotting library in Lab 5, and I suggest you refer to your work there to remind yourself of all of the subtelties. As you may recall, there are various ways to make a seaborn boxplot, and in this case, you will probably want:\n","\n","```sb.boxplot(x=var1,y=var2,notch=True)```\n","\n","where column (x) containins a categorical variable and column (y) containins a numerical variable and you want to compare the distributions of variable y according to the categories stored in column x. Remember that you will need to turn these columns into numpy arrays, as you did in the histogram exercise above. \n","\n","(i) Play around with inputs (e.g. column name) until you find a case (dataframe column) where you think the boxlot tells you something important or interesting. Display your boxplot and then write a 2-3 sentence explanation of what it shows.  \n","    \n","(ii) Play around some more until you find an example where the boxplot is not a particularly good way to represent the data. Explain why in 2-3 sentences. \n","    \n","(iii) Now think more broadly. When are boxplots useful and when aren't they? How many and what types of variables are they good at representing? What do they show that other types of plots (e.g. histogram) don't and what don't they show that other types of plots do? "]},{"cell_type":"code","metadata":{"id":"5Pi4dmCELg88"},"source":["#informative boxplot code here"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6xwUUY6JLg88"},"source":["*Informative boxplot explanation here*"]},{"cell_type":"code","metadata":{"id":"k4d47kf2Lg88"},"source":["#uninformative boxplot code here"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AsGoHFvGLg88"},"source":["*Uninformative boxplot explanation here*"]},{"cell_type":"markdown","metadata":{"id":"i80lyI5pLg88"},"source":["*Part iii explanation here*"]},{"cell_type":"markdown","metadata":{"id":"c3Povi78Lg88"},"source":["--- \n","### Exercise 2c - Scatter Plots\n","---\n","The syntax for creating a scatter plot in pandas is: \n","\n","```dataframe.plot.scatter(x='column name',y='column name')```\n","\n","But here again, the matplotlib.pyplot version is much more versatile. This time, YOU should figure out how to make a matplotlib scatterplot that is interesting or informative from two pandas dataframe columns. \n","    \n","(i) Play around with scatterplot syntax until you understand thoroughly what the options are. Play around with inputs (e.g. column name) until you find a case (dataframe column) where you think the scatterplot tells you something important or interesting. Display your boxplot and then write a 2-3 sentence explanation of what it shows.  \n","    \n","(ii) Play around some more until you find an example where the scatterplot is not a particularly good way to represent the data. Explain why in 2-3 sentences. \n","    \n","(iii) Now think more broadly. When are scatterplots useful and when aren't they? How many and what types of variables are they good at representing? What do they show that other types of plots (e.g. histogram, boxplot) don't and what don't they show that other types of plots do? "]},{"cell_type":"code","metadata":{"id":"8DEgSTO7Lg89"},"source":["#informative scatter plot here"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AXrByQd8Lg89"},"source":["*Informative scatter plot explanation here*"]},{"cell_type":"code","metadata":{"id":"B3t5OI9CLg89"},"source":["#uninformative scatter plot here"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZsxEHvIOLg89"},"source":["*Uninformative scatter plot explanation here*"]},{"cell_type":"markdown","metadata":{"id":"TtUxx0bALg8-"},"source":["*Part iii explanation here*"]},{"cell_type":"markdown","metadata":{"id":"VpfFQhryLg8-"},"source":["---\n","## 3.  Filtering/ Selecting a Subset of Data\n","\n","You will find it quite useful for the rest of this class to be able to select subsets from larger tabular datasets/pandas dataframes. One basic form of filtering employs conditionals inside of square brackets. For example:"]},{"cell_type":"code","metadata":{"id":"3ZcDZzq-Lg8-"},"source":["x = np.array(np.arange(10))\n","print(x)\n","y=x[x > 3]\n","print(y)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bsQ3GodkPFzP"},"source":["for filtering a dataframe, the basic pattern is:\n","\n","```df_filtered = df[df[colname]==value]```\n","\n","Let's break this down a little. The basic syntax is \n","\n","```df_filtered = df[conditional]```\n","\n","Which basically just means that the new dataframe ```df_filtered``` is a subset of dataframe ```df``` that meets the conditional inside the square brackets. \n","\n","The conditional inside the square brackets can be very versatile. In this case it's saying find only places where a single column \n","```df[column]``` \n","has some value \n","```value```\n",". A simple modification would be that the conditional \n","```==```\n"," could be any conditional (e.g \n"," ```>=```\n"," , \n"," ```!=```\n"," , \n"," ```in```\n"," , \n"," ```not```\n"," , etc.). The whole conditional statement could also be compound or more complicated than a simple single value, for example\n","\n","```df_filtered = df[(df[colname]==value) and (df[colname2]==value2)]```\n","\n","or \n","\n","```df_filtered = df[df[colname] in [value1, value2, value3]]```\n","\n","In my opinion, this form of \"pythonic\" data filtering is one of the most powerful things about python as a computing language, and it will benefit you greatly in this class to develop comfort with this style of syntax, so challenge yourself to always filter data this way rather than using loops through the data. \n","\n","Although most filtering can be accomplished in one line of code, in my experience it takes a while to master, so let's begin practicing with Exercise 2 below. "]},{"cell_type":"markdown","metadata":{"id":"HuQbrcEYLg8-"},"source":["--- \n","### Exercise 3\n","--------------\n","\n","Write a function called \"filter\" that takes a dataframe, column name, and value for that column as input and returns a new dataframe containing only those rows where column name = value. For example \n","```filter(df, \"COLNAME\", 1)``` \n","should return a dataframe where all values in the COLNAME column are 1. I recommend printing the dataframe to a file or to the terminal to verify that your function is working. "]},{"cell_type":"code","metadata":{"id":"5fecnE-PLg8-"},"source":["#your function here"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_xTQEZ2ILg8-"},"source":["#your tests here"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kG-_A8C4X54C"},"source":["---\n","# Sumbitting Prelabs and Labs for Grading\n","\n","Before submitting any Google Colab notebook for grading, please follow the following steps\n","\n","**1) Try running everything in one go (Runtime menu -> Restart and run all)**\n","\n","Make sure the entire notebook runs from start to finish. If necessary, comment out any un-executable cells from the instructions portion of the lab so the whole notebook will execute in one go. \n","\n","**2) Restart the kernel (Runtime menu --> Restart Runtime).**\n","\n","**3) Clear all output (Edit --> clear all outputs).**\n","\n","**4) Make sure the names of all group members are in a markdown cell at the top of the file and submit the notebook through the Moodle link for this Lab**"]}]}