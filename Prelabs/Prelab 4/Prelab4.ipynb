{"nbformat":4,"nbformat_minor":0,"metadata":{"anaconda-cloud":{},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"Prelab4.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"Od8nv8p7F-m0"},"source":["### **Your Name Here**"]},{"cell_type":"markdown","metadata":{"id":"D6A5gECS9I3m"},"source":["# Prelab 4 - Intro to Fitting Data\n","\n","\n","### Prelab 4 Contents\n","\n","1. Noise, Data, Model\n","2. Residuals  \n","  2.1 Defining and Plotting Residuals  \n","  2.2 Summing Residuals  \n","  2.3 Comparing Residuals \n","3. Model Fitting  \n","  3.1 Optimization  \n","  3.2 Overfitting  \n","  3.3 Fitting with error bars  \n","  3.4 Weighted Least-Squares fitting  \n","4. Fitting and Hubble's Law  "]},{"cell_type":"code","metadata":{"id":"ESxem3H09I3r"},"source":["#the usual import statements\n","import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oQGCT2_N9I3r"},"source":["### 1. Noise, Data, Model\n","\n","One of the most useful tools in an astronomer's toolkit is model fitting. At it's most basic level, this just means comparing data to a function and using any differences to gauge how fully that function describes the data. \n","\n","Let's start with simple linear fitting. To simulate some \"real\" data, we'll draw numbers from a model like y=mx+b, but then add some random noise to them. Luckily, numpy has lots of great random number generation functions that we'll use extensively later in the class. As you can see from the output, the code below will generate an array of 21 numbers randomly distributed between -0.5 and 0.5."]},{"cell_type":"code","metadata":{"id":"lvPN00S_9I3s"},"source":["#generate 21 random numbers from a flat distribution (all values equally probable) with values between 0 and 1. \n","#subtract 0.5 so that the numbers now range from -0.5 and 0.5, which we'll call \"noise\"\n","noise = (np.random.rand(21)-0.5)\n","#eventually we'll add this to our model to synthesize data, but for now let's just print it so we can verify\n","noise"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vJqTPgSlDWB5"},"source":["Now let's create a simple model. First we'll generate an independent variable, x, that ranges from 0 to 20"]},{"cell_type":"code","metadata":{"id":"2vp7fmG59I3s"},"source":["x = np.arange(21)\n","x"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AcQxKz9jDgQx"},"source":["Now let's generate a bunch of y points equal to twice the x values. In other words, following the function y=2x. This function is what we'll refer to as the \"model\" throughout, so we'll name it as such."]},{"cell_type":"code","metadata":{"id":"L0GxmYGHDgpp"},"source":["model=2*x\n","model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vFz5CzspD0_w"},"source":["Of course, even when physical laws are a simple as y=2x, in nature we never measure things so perfectly. Imperfections in our detectors, human error, unaccounted for physical effects, etc. all create \"noise\" such that real data NEVER perfectly matches a physical model. So we need some imperfect data to compare this model to if we're going to explore mdoel fitting. Let's make some synthetic \"data\" by adding the \"noise\" we've already created to our \"model\". "]},{"cell_type":"code","metadata":{"id":"OtcBDZfs9I3t"},"source":["data=model+noise"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"op_KxWPFE-ni"},"source":["And now let's plot it"]},{"cell_type":"code","metadata":{"id":"17IeLxyG9I3t"},"source":["#plot synthetic data with points and model with dashed red line\n","plt.plot(x,data, 'bo', label='data')\n","plt.plot(x,model,'r--', label='model')\n","plt.xlim(0,20)\n","plt.xlabel(\"independent variable\")\n","plt.ylabel(\"dependent variable\")\n","plt.title(\"tight scatter\")\n","plt.legend()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"leqxxbRE9I3t"},"source":["OK so that's a bit ridiculous. If you squint you can see that the values don't fall perfectly on the line, but clearly they're not very far off either. Let's make our \"noise\" more dramatic, and then plot again. "]},{"cell_type":"code","metadata":{"id":"OFGBo4U_9I3t"},"source":["#make noisier noise (between -5 and 5)\n","noise2 = (np.random.rand(21)-0.5)*10\n","noise2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5NkBpUOt9I3t"},"source":["#make and plot this new set of data\n","data2 = model+noise2\n","plt.plot(x,data2, 'bo', label='data')\n","plt.plot(x,model, 'r--', label='model')\n","plt.xlabel(\"independent variable\")\n","plt.ylabel(\"dependent variable\")\n","plt.title(\"larger scatter\")\n","plt.legend()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SsrV_-RpFKef"},"source":["---\n","Exercise 1 \n","\n","---\n","\n","Do the same thing yourselves for a slightly more complex \"model\" - one with a slope and an intercept. Generate an independent variable and a model that follows some y=mx+b functional form. Then, generate synthetic \"data\" with a reasonable scatter to mimic what you think \"real\" data might look like, and then plot the data and model on the same plot."]},{"cell_type":"code","metadata":{"id":"WbDCPNrhFmyU"},"source":["#define independent variable"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"D_GFoFd7FnUO"},"source":["#define model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WLO8vPfOFrNX"},"source":["#define noise"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_4NpJ9uXFrkb"},"source":["#create synthetic data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NIcI-ahTFz7v"},"source":["#plot"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9aM7IGAx9I3u"},"source":["---\n","\n","## 2. Residuals \n","\n","### 2.1 Defining and Plotting Residuals\n","\n","As discussed in the readings, when we have data and a model fit, one way to assess the quality of the fit is to look at the residuals, so let's do that. If your model is defined at all the same points as your data, this is simple. To make residuals, all you have to do is subract your model from your data. \n","\n","Note that in many cases this may not be the case, and you might have to \"interpolate\" your model to predict the value it would have at all the same x locations as your data points. We won't do this right now, but keep it in mind for the future."]},{"cell_type":"code","metadata":{"id":"rAWIdgAP9I3u"},"source":["#define residuals\n","residuals = data2-model\n","\n","#plot them\n","plt.plot(x, residuals, 'rx')\n","#plot a \"perfect fit\" line at residual value = 0\n","plt.plot([0,20],[0,0],'--')\n","plt.ylim(-5,5)\n","plt.xlim(0,20)\n","plt.ylabel('residual (data - model)')\n","plt.xlabel('independent variable')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WCqd5xbuG0xX"},"source":["---\n","### Exercise 2\n","---\n","\n","What sorts of things should you look for in residual plots? What patterns indicate a high-quality fit, and what patterns might indicate that your model is not a good fit to the data? In your own words, describe at least two patterns for each case (good and bad fit)."]},{"cell_type":"markdown","metadata":{"id":"JRj6NrvCIqTO"},"source":["***Your answer here***"]},{"cell_type":"markdown","metadata":{"id":"XWHEZfxG9I3u"},"source":["---\n","\n","### 2.2 Summing Residuals\n","\n","Residuals are a great way to judge quality of fit qualitatively, and residual plote appear often in the astronomical literature, but when comparing multiple possible models to data we often want a ***quantitative** way to judge the quality of fit. \n","\n","The simplest of these metrics is just to sum the residuals. In this case, we want the DISTANCE from the line rather than the difference, because otherwise points above and below the line will cancel one another and we are looking for a measure of how far away from zero they are on average."]},{"cell_type":"code","metadata":{"id":"NJObP3ld9I3u"},"source":["#squaring and square rooting gives us only positive distances \n","residuals_mag = np.sqrt((residuals)**2)\n","residuals_mag"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fO5jyJSC9I3v"},"source":["#then add them all up to get a total measure of the distances between the data points and the model\n","total_error_mag = sum(residuals_mag)\n","total_error_mag"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FszMcQAb9I3v"},"source":["More common in quality of fit metrics is to take the square of the distances between data points and the model, rather than just the distance. This gives a little extra penalty to points that are far away from the model."]},{"cell_type":"code","metadata":{"id":"Lx3ks_Sz9I3v"},"source":["#or we can take the squares, as is more commonly done\n","residuals_sq = residuals**2\n","residuals_sq"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TT8c_5Se9I3v"},"source":["#then add them all up to get a total measure of the magnitudes\n","total_error_sq = sum(residuals_sq)\n","total_error_sq"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sMBucRjN9I3v"},"source":["These sums are the numbers that you're trying to minimize when doing \"least-squares\" fitting, which is the most common type of model fitting in astronomy. \n","\n","One important note is that the sum of the residuals or the squared residuals generates a number that has relatively little meaning in isolation. Indeed, the trick with quality of fit metrics is often the context. The number only means something relative to another fit of the same type applied to the same data. "]},{"cell_type":"markdown","metadata":{"id":"hW55t8lO9I3w"},"source":["### 2.3. Comparing Residuals\n","\n","The examples I've given so far have been pretty contrived. Data are of course not usually generated from a model. Rather, they are generated by the physical laws that govern the universe and we have to come up with the models that we think best describe them. Now, let's assume that I have only the data and no knowledge of the underlying model relationship"]},{"cell_type":"code","metadata":{"id":"7qJz1sxt9I3w"},"source":["#some data I collected\n","plt.plot(x, data2, 'go')\n","plt.xlabel(\"independent variable\")\n","plt.ylabel(\"dependent variable\")\n","plt.title(\"no fit\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ylvnoV899I3w"},"source":["In exploring the data and developing a model, I might first want to know something about the value of the correlation coefficient R for these two variables"]},{"cell_type":"code","metadata":{"id":"dSMyomik9I3w"},"source":["#there are lots of ways to do this in python. here's one\n","from scipy.stats.stats import pearsonr\n","#the output is the correlation coefficient R and the \"p value\", a measure of significance that we'll talk about later\n","pearsonr(x,data2)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6_pKEMGaSAs7"},"source":["I might have an idea of roughly what functional form the underlying physical law should take, or two different models that I want to test against one another. For example:"]},{"cell_type":"code","metadata":{"id":"4ioPbLKv9I3w"},"source":["#this sum of squares metric might also allow me to judge the quality of one model relative to another. For example:\n","model2 = 2.1*x-1\n","plt.plot(x,data2, 'go')\n","plt.plot(x,model)\n","plt.plot(x,model2,'r--')\n","plt.xlabel(\"independent variable\")\n","plt.ylabel(\"dependent variable\")\n","plt.title(\"potential fits\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yhIntQsKSYAj"},"source":["They both look like reasonable matches to the data, so how do I know which one matches better?. I could start with the residuals:"]},{"cell_type":"code","metadata":{"id":"44ovG18RShBJ"},"source":["model2 = 2.1*x-1\n","plt.plot(x,data2-model, 'go', label='model 1')\n","plt.plot(x,data2-model2, 'rx', label='model 2')\n","plt.plot([0,20],[0,0],'k')\n","plt.xlabel(\"independent variable\")\n","plt.ylabel(\"residual\")\n","plt.legend\n","plt.title(\"potential fits\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Mqz_A_dFTD2Z"},"source":["If these models were more different from one another we might be able to judge which is better by eye, but in this case it's rather ambiguous from looking at the residuals which model is a better fit. Instead, we can use the sum of squared residuals as a quantitative metric. Since we're using the same metric to compare two models to the same data, these two numbers do now have meaning relative to one another. The one with the lower value is the better fit. "]},{"cell_type":"code","metadata":{"id":"mdWNcvsj9I3w"},"source":["error1 = sum((model-data2)**2)\n","error2 = sum((model2-data2)**2)\n","print(\"sum of squares for model 1 (true) is \", error1)\n","print(\"sum of squares for model 2 is \",error2)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HqFQv0C19I3x"},"source":["Note that if you execute all these cells multiple times, not infrequently the quality of fit metric for the alternate model will be better than the \"true\" model. The \"truth\" in the case of model fitting is elusive. We only know what the data tell us, and real data are never a perfect representation of truth. We can only do our best given the data we have and design other independent experiments to test our models. "]},{"cell_type":"markdown","metadata":{"id":"sFc7pEk3RsSj"},"source":["---\n","### Exercise 3\n","---\n","\n","(a) Write a simple function with three required inputs - an array of independent variable values, the coefficients (slope, intercept) for a linear model, and an array of data values. The function should create a residual plot, and compute and print the sum of squared residuals. \n","\n","(b) Using your independent variable and data arrays from exercise 1 and your function from part (a), vary the slope of the model by hand until you acheive the lowest possible value of the sum of squared residuals. Keep the intercept fixed at the value you defined in exercise 1 and vary the slope until you have the \"best fit\" slope for your \"data\" to two decimal places. \n","\n","(c) Write a paragraph explaining why your \"true\" model (from which you generated the data, the functional form that you defined in Exercise 1) is not the same as the \"best fit\" model. Your explanation should integrate descriptions of the residual plots and the quantitative values of the sum of squared residuals for both models. What deeper truths does this reveal about the process of model fitting?"]},{"cell_type":"markdown","metadata":{"id":"_V2tXM9a9I3x"},"source":["---\n","\n","## 3. Model Fitting\n","\n","### 3.1 Optimization\n","\n","Of course there are more sophisticated ways to choose a model besides simple trial and error. At their most basic level, these are often built around the idea of minimizing the distances of the residuals from zero.\n","\n","Python has lots of built-in functionalities for this kind of thing. My preferred methodm and the most generic/tunable choice, is using the scipy optimization module "]},{"cell_type":"code","metadata":{"id":"TyGVigsr9I3y"},"source":["#now let's try a more general model fitting function\n","import scipy.optimize as optimization"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7gyTsIyq-sk9"},"source":["Under the optimization module, you have to define a general functional form for the fit line BUT NOT THE SPECIFIC VALUES FOR THE COEFFICIENTS, etc. \n","\n","For example, for linear (straight line) fits this could take two forms. A line without an intercept (a line starting at the origin)\n","\n","$$y=mx$$\n","\n","or a line with an intercept\n","\n","$$y=mx+b$$\n","\n","The function that we need to define and pass into scipy.optimize is just a python definition of these functions - something that takes in an independent variable (x) and the tunable parameters of the line (slope or slope and intercept) and returns the y value. "]},{"cell_type":"code","metadata":{"id":"EuYauHsH9I3y"},"source":["\n","#line without an intercept (intercept zero)\n","def slopefunc(x,sl):\n","    return sl*x\n","\n","#line with an intercept\n","def slopeintfunc(x,sl,incpt):\n","    return sl*x+incpt"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RnCsd_u-_x0g"},"source":["The nice thing about scipy.optimize as opposed to certain built-in linear regression (straight line fitting) functions, is that this extends easily to more complicated functional forms and is not limited to straight line fits. For example, you can just as easily write a quadratic function of the form:\n","\n","$$y=a+bx+cx^2$$"]},{"cell_type":"code","metadata":{"id":"8FTtgGfj_z_D"},"source":["#quadratic function\n","def quadfunc(x,a,b,c):\n","    return a+b*x+c*x*x"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"anXmsp5sAJa3"},"source":["Now that we've defined the some functional forms for our fit lines, we can do the optimization itself with the function curve_fit, where the arguments are the name of the function we wrote describing the functional form of the line (in this case, a line with an intercept ```slopeintfunc```), and the independent (```x```) and dependent (```data2```) data arrays."]},{"cell_type":"code","metadata":{"id":"4OmKo1U19I3y"},"source":["#then use curve_fit\n","fit = optimization.curve_fit(slopeintfunc,x,data2)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JEek-1bbBxkS"},"source":["The object returned by the ```curve_fit``` function (which we have here called ```fit```) is a tuple. The first element contains the \"best fit\" values for whatever the tunable parameters are in your model (in our case slope and intercept). "]},{"cell_type":"code","metadata":{"id":"E3i17MEmCOjn"},"source":["#best fit parameters (sl, int)\n","fit[0]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"o1oVfxK3C6qM"},"source":["As you can see, the first element of the tuple is itself a list containing the best fit values for the tunable parameters. Let's extract them individually."]},{"cell_type":"code","metadata":{"id":"KUXIP3QMDCvY"},"source":["best_slope = fit[0][0]\n","best_intercept = fit[0][1]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"26sOYPFTCieI"},"source":["The next element of the tuple contains what's called the covariance matrix, which can also be quite useful. We will explore covariance matrices in more detail in Unit 2 of the course. "]},{"cell_type":"code","metadata":{"id":"1HwVj4lY9I3y"},"source":["#covariance matrix\n","fit[1]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uYe7upD2CuHK"},"source":["The best sanity check after you've done a fit is to overplot it on the data. Does it match the data well?"]},{"cell_type":"code","metadata":{"id":"4X7n9g6f9I3y"},"source":["#plot the data\n","plt.plot(x,data2, 'go', label='data')\n","#plot the model\n","plt.plot(x, slopeintfunc(x,best_slope,best_intercept), label='linear model (m=1.96, b=0.21)')\n","#labels\n","plt.legend()\n","plt.xlabel(\"independent variable\")\n","plt.ylabel(\"dependent variable\")\n","plt.title(\"least squares fit\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IAAhVZkxERS7"},"source":["---\n","### Exercise 4\n","---\n","\n","(a) Define for yourself a general cubic function of the form \n","$$y=a+bx+cx^2+dx^4$$ \n","(b) using curve_fit, extract the optimal values for the a, b, c, and d coefficients.   \n","(c) overplot this fit (define the coefficients in your legend label) on our made up data (x, data2).   \n","(d) describe in words how this fit differs from the linear fit I did for you above. Which is a better fit to the data in your opinion and what criteria are you using to judge?  \n"]},{"cell_type":"code","metadata":{"id":"MvT-2zCcHegV"},"source":["#your cubic function definition goes here"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AerRu9ENHjEL"},"source":["#your curve fit goes here"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xmqWRe8aHjYr"},"source":["#your plot goes here"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VIYYu303IlTR"},"source":["***Your explanation for part d goes here***"]},{"cell_type":"markdown","metadata":{"id":"zpGN4rl49I3z"},"source":["---\n","### 3.2 Overfitting\n","\n","Since we can define functions to arbitrary dimensions, fitting can definitely can get a bit out of control. For example:"]},{"cell_type":"code","metadata":{"id":"jCtejakh9I3z"},"source":["def tenparamfunc(x,a,b,c,d,e,f,g,h,i,j):\n","    return a+b*x+c*x**2+d*x**3+e*x**4+f*x**5+g*x**6+h*x**7+i*x**8+j*x**9"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GY1Led7w9I3z"},"source":["fit2 = optimization.curve_fit(tenparamfunc,x,data2)\n","fit2[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"v8Q9of859I30"},"source":["plt.plot(x,data2, 'go')\n","c = fit2[0]\n","plt.plot(x, tenparamfunc(x,c[0],c[1],c[2],c[3],c[4],c[5],c[6],c[7],c[8],c[9]))\n","plt.xlabel(\"independent variable\")\n","plt.ylabel(\"dependent variable\")\n","plt.title(\"fit for function with ten parameters\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3pb4JDnc9I30"},"source":["A simple but important rule of thumb is:\n","\n","> ***The number of parameters in your model should be <<< the number of data points***"]},{"cell_type":"markdown","metadata":{"id":"e5ZfHHMd9I30"},"source":["### 3.3 Fitting with error bars"]},{"cell_type":"markdown","metadata":{"id":"EVOKaxxb9I30"},"source":["Often we know enough about how our measurements are taken that we can assign \"error bars\" or \"uncertainties\" to our measurements. These uncertainties can take two forms. \n","\n","***Homoschedastic*** errors are the same for every point. These tend to happen when you have some standard uncertainty associated with a certain type of measurement or measurement apparatus. \n","\n","***Heteroschedastic*** errors vary from one data point to the next and are generally a property of the data themselves. In the example below, the error on each value is equal to its square root. This is basically the defintion of uncertainty for poisson-based statistical processes, and is therefore very common in astronomy. \n","\n","The cell below defines a homoschedastic and a heteroschedastic array of errors, one for each point in our dataset."]},{"cell_type":"code","metadata":{"id":"0QRQiJLv9I30"},"source":["# equal errors (homoschedastic)\n","#an array of threes\n","errors_uniform = np.ones(21)*3\n","\n","#errors that vary (heteroschedastic)\n","errors_poisson = np.sqrt(data2)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"noVOPq2JJ8Go"},"source":["To plot data points with error bars, there is a very handy built in function called errorbar that allows you to specfy values for ```yerr``` and ```xerr``` (y and x error bars). These should be arrays or lists with the same number of entries as you have datapoints."]},{"cell_type":"code","metadata":{"id":"05Tf4-0Y9I30"},"source":["#visualize the homoschedastic errors\n","plt.errorbar(x,data2,yerr=errors_uniform, fmt='go')\n","plt.xlim(0,20)\n","plt.xlabel(\"independent variable\")\n","plt.ylabel(\"dependent variable\")\n","plt.title(\"homoschedastic error bars\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2DKIFyPn9I31"},"source":["plt.errorbar(x,data2,yerr=errors_poisson, fmt='go')\n","plt.xlim(-1,21)\n","plt.xlabel(\"independent variable\")\n","plt.ylabel(\"dependent variable\")\n","plt.title(\"heteroschedastic error bars\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-Mv-bsbr9I31"},"source":["### 3.4 Weighted Least Squares Fitting\n","\n","If we want to take the uncertainty in each of our data points into consideration in calculating goodness of fit, we can extend this to assigning \"weights\" to each data point. \n","\n","Since larger error bars indicate greater uncertainty, these data points should be assigned less weight than other data points with smaller error bars. \n","\n","A weight is just like a coefficient in front of the (data-model)$^2$ calculation typical to least squares. More formally:\n","\n","$$ Q = \\sum_{i=1}^nw_i[y_i-f(x_i,\\beta)]^2$$\n","\n","Where $x_i$ is the independent variable, $y_i$ are the observed values, $f(x_i,\\beta)$ is the model with some set of parameters $\\beta$ and $w_i$ are the weights for each datapoint\n","\n","A common weight is the reciprocal of the error value squared, or $\\frac{1}{\\sigma^2}$. Sigma here is the value of the error bar and is not to be confused with a standard deviation, though standard deviation values are often assigned as errors. \n","\n","Let's do this for our example of heteroschedastic error bars above"]},{"cell_type":"code","metadata":{"id":"m8LqelEC9I31"},"source":["lsq_weighted=sum(1/errors_poisson**2*(data2-model)**2)\n","lsq_weighted"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9YSaIkKb9I32"},"source":["Oops what happened? Well, the model value at x=0 is 0 in this case, and the errors are too, so our 1/errors_poissson statement becomes problematic because we can't divide by zero. \n","\n","We can fix this by removing the datapoint from consideration (indeed it's rare that we measure something to be zero anyway, so it was a bit contrived to begin with). \n","\n","Let's do that and also compute a new dependent ```model3```, simulated dataset ```data3``` and poisson error array ```errors_poisson3```"]},{"cell_type":"code","metadata":{"id":"LTg8x-Du9I32"},"source":["#new independent array, starting at 1\n","x3=np.arange(20)+1\n","#new y-2x dependent variable for that array\n","model3=2*x3\n","#random noise\n","noise3 = (np.random.rand(20)-0.5)*10\n","#simulated data\n","data3= 2*x3+noise3\n","#poisson errors \n","errors_poisson3 = np.sqrt(data3)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"I2wTALruPsLA"},"source":["Now let's compute the ***weighted*** sum of squares vlaue, which we could use as a quality of fit metric to compare two models where we know something about uncertainties. "]},{"cell_type":"code","metadata":{"id":"PAiuZLcD9I32"},"source":["#compute the weighted least-squares value \n","lsq_weighted=sum(1/errors_poisson3**2*(data3-model3)**2)\n","lsq_weighted"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OpHrJtFz9I32"},"source":["Similarly, we can build in the uncertainties/weights when we do the least squares fit to the data. This functionality is built into the curve_fit function through the optional ```sigma``` parameter). \n","\n","Let's compute the fit again here with and without the weights, so that we can compare the two fits visually. "]},{"cell_type":"code","metadata":{"id":"4l1oSlLz9I32"},"source":["fit_weighted = optimization.curve_fit(slopeintfunc,x3,data3, sigma=errors_poisson3)\n","fit_unweighted = optimization.curve_fit(slopeintfunc,x3,data3)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"V2k7e8ib9I32"},"source":["#plot data\n","plt.errorbar(x3,data3,yerr=errors_poisson3, fmt='go')\n","plt.xlim(0,21)\n","plt.ylim(0,50)\n","#plot weighted and unweighted fits\n","plt.plot(x3, slopeintfunc(x3,fit_weighted[0][0],fit_weighted[0][1]), label='weighted')\n","plt.plot(x3, slopeintfunc(x3,fit_unweighted[0][0],fit_unweighted[0][1]), 'r--', label='unweighted')\n","#labels\n","plt.legend(loc='lower right',)\n","plt.xlabel(\"independent variable\")\n","plt.ylabel(\"dependent variable\")\n","plt.title(\"weighted vs. unweighted fits\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"I3XGG7OJ9I33"},"source":["optimization.curve_fit?"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g27ayg1uBkgr"},"source":["## 4. Fitting and Hubble's law\n","\n","For lab 4, you will work with a classmate to process and fit both the original data leading to the derivation of an important astrophysical law known as \"Hubble's Law\", which basically amounts to a discovery that the universe is expanfing, and more modern measurements of the same quantities. The next two exercises will get the tedious bits of reading in and familiarizing yourself with the data so that you can do the hard parts (manipulating and fitting) done in lab. "]},{"cell_type":"markdown","metadata":{"id":"w4lFuXMUviwa"},"source":["--- \n","## Exercise 5\n","---\n","\n","In the cell below, I have transcribed the data from Edwin Hubble's original 1928 paper \"A relation between distance and radial velocity among extra-galactic nebulae\", available [here](https://www.pnas.org/content/pnas/15/3/168.full.pdf).\n","\n","a.  Open the original paper (in the Drive folder for this prelab). Use it and your knowledge of Python code to decipher what each line in the next two code cells is doing. Add a comment at the top of each line stating what it is doing and/or where in the paper it came from.   \n","b. Create a scatter plot from Hubble's data. To make a scatterplot in python, you use the same plt.plot function that we used for line graphs last week except after the x and y arguments, you add a string describing the type of plotting symbol that you want. [Here](https://matplotlib.org/3.1.1/api/markers_api.html) is a list of plot symbols. Note that you can combine these with colors so, for example, 'go' is green circles and 'rx' is red xs. Give your plot a title and axis labels to match Hubble's original.  \n","c. Write code that will print each entry in the list obj_list on its own line (you will need this for exercise 2, below)."]},{"cell_type":"code","metadata":{"id":"5wUKASCiviwa"},"source":["NGC_nos = [6822,598,221,224,5457,4736,5194,4449,4214,\n","        3031,3627,4826,5236,1068,5055,7331,4258,\n","        4151,4382,4472,4486,4649]\n","obj_list = ['SMC', 'LMC']\n","for i in np.arange(len(NGC_nos)):\n","    obj_list.append('NGC '+str(NGC_nos[i]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tF_PDweQviwb"},"source":["dists = np.array([0.032,0.034,0.214,0.263,0.275,0.275,0.45,0.5,0.5,0.63,0.8,0.9,0.9,\n","         0.9,0.9,1.0,1.1,1.1,1.4,1.7,2.0,2.0,2.0,2.0])#Mpc\n","vels = np.array([170.,290,-130,-70,-185,-220,200,290,270,200,300,-30,650,150,500,920,450,500,500,960,500,850,800,1000]) #km/sec"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xxslEPwRviwb"},"source":["#plot goes here"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Yz0CmA4uviwb"},"source":["#loop to print names goes here"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4NB1_l_Sviwb"},"source":["---\n","    \n","## Exercise 6\n","---\n","Now, let's pull modern data for Hubble's galaxies. Copy and paste the list from Exercise 5c into the query form [here](http://ned.ipac.caltech.edu/forms/gmd.html). ***Before you click \"Submit Query\"***, scroll to the check boxes at the bottom of the page and make sure to check ***only*** the following:\n","  *  User Input Object Name\n","  *  Redshift\n","  *  Redshift Uncertainty  \n","  And in the bottom right panel:  \n","  *  Metric Distance\n","  *  Mean\n","  *  Standard Deviation\n","  *  Number of measurements\n","\n","Open a simple text editor application (e.g. \"TextEdit\" on a Mac) and copy and paste the table into it. Save it as cat.txt and place it in your google drive. You may want to be sure that you're saving it as plain rather than formatted text as well. Most text editors have an option to do this in the format menu or at the file saving stage.\n","\n","The code cells below will \"read in\" the data using a python package called Pandas that we will learn about in great detail in the coming weeks. For now, just execute the cell below, which will create python lists stored in variables with descriptive names from your cat.txt file. \n","\n","a)Describe in words at least two patterns that you note in the tabular data  \n","b) Make a histogram for each of the following quantities: redshift, redshift_uncert, dist, and dist_uncert. All your plots should have axis labels, and for the histograms you should play around with the number of bins until you can justify your choice for this value.  Discuss and compare the shapes of the distributions for each of the quantities in general, qualitative terms.   \n","c) Plot the uncertainty in redshift as a function of redshift for these galaxies and the uncertainty in distance as a function of distance. What patterns do you notice, if any in the relationships between these quantities and their uncertainties?  "]},{"cell_type":"code","metadata":{"id":"whw9D1_eU35j"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xB5q41duVAg-"},"source":["#modify the path below to match wherever you've stored your cat.txt file (this is just for your main Google Drive folder)\n","path_to_cat = '/content/drive/MyDrive/cat.txt'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BYY30qjvviwb"},"source":["#import the necessary module\n","import pandas\n","#define columns\n","cols = ['Obj Name', 'Redshift', 'Redshift Uncert', 'Dist Mean (Mpc)', 'Dist Std Dev (Mpc)', 'Num Obs']\n","#read in the file\n","df = pandas.read_csv(path_to_cat, delimiter ='|', skiprows=3, header = 0, names = cols, skipinitialspace=True)\n","\n","#extract the relevant values as lists\n","redshift = df[\"Redshift\"].tolist()\n","redshift_uncert = df[\"Redshift Uncert\"].tolist()\n","dists2 = df[\"Dist Mean (Mpc)\"].tolist()\n","dists2_uncert = df[\"Dist Std Dev (Mpc)\"].tolist()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cwKxFSMKviwc"},"source":["#display table (python \"data frame\" object)\n","df"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"W629AJbwviwc"},"source":["***Answer to Part a***"]},{"cell_type":"code","metadata":{"id":"zN1Y28mVviwc"},"source":["#plots for part b - redshift"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Bk6pdaE1viwc"},"source":["#plots for part b - redshift uncertainty"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0Nl5g35lviwc"},"source":["#plots for part b - distance"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CGHTTqgSviwc"},"source":["#plots for part b - distance uncertainty"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"collapsed":true,"id":"Ir1ZnBgWviwd"},"source":["***Part B explanation***"]},{"cell_type":"code","metadata":{"id":"Iwi-M8n6viwd"},"source":["#part c scatter plot 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VyocEKAcviwd"},"source":["#part c scatter plot 2"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4CTJKnGWviwd"},"source":["***Part C explanation***"]},{"cell_type":"markdown","metadata":{"id":"n4J_40xgdAY2"},"source":["# Sumbitting Prelabs and Labs for Grading\n","\n","Before submitting any Google Colab notebook for grading, please follow the following steps\n","\n","**1) Try running everything in one go (Runtime menu -> Restart and run all)**\n","\n","Make sure the entire notebook runs from start to finish. If necessary, comment out any un-executable cells from the instructions portion of the lab so the whole notebook will execute in one go. \n","\n","**2) Restart the kernel (Runtime menu --> Restart Runtime).**\n","\n","**3) Clear all output (Edit --> clear all outputs).**\n","\n","**4) Make sure the names of all group members are in a markdown cell at the top of the file and submit the notebook through the Moodle link for this Lab**"]}]}